{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "rpYGw1etWG8s",
    "outputId": "ad14e6e2-e5e8-4715-f01d-710e2d177372",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ray\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import optuna\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5sA9GgKwWWMM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, x, y, target_transform = False):\n",
    "    self.labels = y\n",
    "    self.spectrum = x\n",
    "    self.target_transform = target_transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    spectra = self.spectrum[idx]\n",
    "    label = self.labels[idx]\n",
    "\n",
    "    if self.target_transform != False:\n",
    "      label = self.target_transform(label)\n",
    "    else:\n",
    "      pass\n",
    "\n",
    "    return torch.tensor(spectra), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3ZgxYDifiI-r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "  def __init__(self, weight = [1, 1, 1], punish_distance = False, punish_Lya = False):\n",
    "    super(customLoss, self).__init__()\n",
    "    self.weight = weight\n",
    "    self.punish_distance = punish_distance\n",
    "    self.punish_Lya = punish_Lya\n",
    "\n",
    "  def forward(self, output, target):\n",
    "    weight = self.weight\n",
    "    target = target.permute(1, 0, 2)\n",
    "\n",
    "    if self.punish_distance == True:\n",
    "      punish = (torch.abs(torch.argmax(output[0], dim = 1) - torch.argmax(target[0], dim = 1)) * torch.sum(target[0], dim = 1) + (output[0] > 0.1).sum(dim = 1) * (1 - torch.sum(target[0], dim = 1)))\n",
    "      punish = (punish / max(torch.sum(punish).item(), 1) * 64).unsqueeze(dim = 1).tile(1, 78)\n",
    "      BCE = nn.BCELoss(reduction = \"mean\", weight = punish)\n",
    "    elif self.punish_Lya != False:\n",
    "      punish = torch.where(torch.sum(target[0], dim = -1) > 0, self.punish_Lya, 1)\n",
    "      punish = ((punish / torch.sum(punish).item()) * 64).unsqueeze(dim = -1).tile(1, 78)\n",
    "      BCE = nn.BCELoss(reduction = \"mean\", weight = punish)\n",
    "    else:\n",
    "      BCE = nn.BCELoss(reduction = \"mean\")\n",
    "\n",
    "    MSE = nn.MSELoss(reduction = \"mean\")\n",
    "    loss_1 = BCE(output[0], target[0])\n",
    "    loss_2 = BCE(output[1], target[1])\n",
    "    loss_3 = MSE(output[2], target[2])\n",
    "\n",
    "    loss_total = weight[0] * loss_1 + weight[1] * loss_2 + weight[2] * loss_3\n",
    "\n",
    "    return loss_total / sum(weight), loss_1, loss_2, loss_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XkfeAzs3BCdB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, kernel_size1_1, kernel_size3_1, kernel_size3_2, kernel_size4_1, kernel_size4_2, ratio, out_channel7, pooling, fc_width1, fc_width2, fc_width3, rescale_1, rescale_2, rescale_3, thres, factor):\n",
    "        self.rescale_1 = rescale_1\n",
    "        self.rescale_2 = rescale_2\n",
    "        self.rescale_3 = rescale_3\n",
    "        self.thres = thres\n",
    "\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        if round(kernel_size1_1 * ratio) % 2 == 0:\n",
    "            kernel_size1_2 = round(kernel_size1_1 * ratio) + 1\n",
    "        else:\n",
    "            kernel_size1_2 = round(kernel_size1_1 * ratio)\n",
    "\n",
    "        if round(kernel_size1_1 * ratio ** 2) % 2 == 0:\n",
    "            kernel_size1_3 = round(kernel_size1_1 * ratio ** 2) + 1\n",
    "        else:\n",
    "            kernel_size1_3 = round(kernel_size1_1 * ratio ** 2)\n",
    "            \n",
    "        if round(kernel_size1_1 * ratio ** 3) % 2 == 0:\n",
    "            kernel_size1_4 = round(kernel_size1_1 * ratio ** 3) + 1\n",
    "        else:\n",
    "            kernel_size1_4 = round(kernel_size1_1 * ratio ** 3)\n",
    "\n",
    "        stride = 1\n",
    "        dilation = 1\n",
    "        out_channel = int(10 * factor)\n",
    "        out_channel2 = int(10 * factor)\n",
    "        out_channel3 = int(20 * factor)\n",
    "        out_channel4 = int(20 * factor)\n",
    "        out_channel5 = int(40 * factor)\n",
    "        out_channel6 = int(80 * factor)\n",
    "        out_channel7 = out_channel7\n",
    "\n",
    "        self.layer1_1 = nn.Sequential(\n",
    "            nn.Conv1d(1, out_channel, kernel_size = kernel_size1_1, stride = stride, padding = kernel_size1_1 // 2, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer1_2 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel, out_channel2, kernel_size = kernel_size1_2, stride = stride, padding = kernel_size1_2 // 2, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel2),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer1_3 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel2, out_channel3, kernel_size = kernel_size1_3, stride = stride, padding = kernel_size1_3 // 2, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size = pooling, stride = pooling - 1, padding = pooling // 2),\n",
    "            )\n",
    "        self.layer1_4 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel3, out_channel4, kernel_size = kernel_size1_4, stride = stride, padding = kernel_size1_4 // 2, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size = pooling, stride = pooling - 1, padding = pooling // 2),\n",
    "            )\n",
    "        self.layer1_5 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel4, out_channel5, kernel_size = 1, stride = stride, padding = 0, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel5),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer1_6 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel5, out_channel6, kernel_size = 1, stride = stride, padding = 0, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel6),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer1_7 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel6, out_channel7, kernel_size = 1, stride = stride, padding = 0, dilation = dilation),\n",
    "            )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(610 * out_channel7, fc_width1),\n",
    "            nn.BatchNorm1d(fc_width1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width1, fc_width1),\n",
    "            nn.BatchNorm1d(fc_width1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width1, fc_width1),\n",
    "            nn.BatchNorm1d(fc_width1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width1, fc_width1),\n",
    "            nn.BatchNorm1d(fc_width1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width1, 78),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        self.layer3_1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 20, kernel_size = kernel_size3_1, stride = stride, padding = kernel_size3_1 // 2, dilation = dilation),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer3_2 = nn.Sequential(\n",
    "            nn.Conv1d(20, 20, kernel_size = kernel_size3_2, stride = stride, padding = kernel_size3_2 // 2, dilation = dilation),\n",
    "            )\n",
    "\n",
    "        self.layer4_1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 20, kernel_size = kernel_size4_1, stride = stride, padding = kernel_size4_1 // 2, dilation = dilation),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer4_2 = nn.Sequential(\n",
    "            nn.Conv1d(20, 20, kernel_size = kernel_size4_2, stride = stride, padding = kernel_size4_2 // 2, dilation = dilation),\n",
    "            )\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(1900, fc_width2),\n",
    "            nn.BatchNorm1d(fc_width2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width2, fc_width2),\n",
    "            nn.BatchNorm1d(fc_width2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width2, fc_width2),\n",
    "            nn.BatchNorm1d(fc_width2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width2, fc_width2),\n",
    "            nn.BatchNorm1d(fc_width2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width2, 1),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Linear(1900, fc_width3),\n",
    "            nn.BatchNorm1d(fc_width3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width3, fc_width3),\n",
    "            nn.BatchNorm1d(fc_width3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width3, fc_width3),\n",
    "            nn.BatchNorm1d(fc_width3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width3, fc_width3),\n",
    "            nn.BatchNorm1d(fc_width3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width3, fc_width3),\n",
    "            nn.BatchNorm1d(fc_width3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width3, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.rescale_1 == \"mean\":\n",
    "            x_scale_1 = x - torch.mean(x, dim = -1, keepdim = True)\n",
    "        elif self.rescale_1 == \"zscore\":\n",
    "            x_scale_1 = (x - torch.mean(x, dim = -1, keepdim = True)) / torch.std(x, dim = -1, keepdim = True)\n",
    "        else:\n",
    "            x_scale_1 = torch.clone(x)\n",
    "\n",
    "        x1_1 = self.layer1_1(x_scale_1)\n",
    "        x1_2 = self.layer1_2(x1_1)\n",
    "        x1_3 = self.layer1_3(x1_2)\n",
    "        x1_4 = self.layer1_4(x1_3)\n",
    "        x1_5 = self.layer1_5(x1_4)\n",
    "        x1_6 = self.layer1_6(x1_5)\n",
    "        x1_7 = self.layer1_7(x1_6)\n",
    "        x1_flatten = x1_7.view(x1_7.size(0), -1)\n",
    "        x2 = self.layer2(x1_flatten)\n",
    "        x2_mask = torch.zeros_like(x2, device = device)\n",
    "        x2_mask[x2 > self.thres] = 1\n",
    "\n",
    "        crop_index1 = torch.round(torch.argmax(x2, dim = -1) * 31.25 + 15.625).unsqueeze(1) + torch.arange(-47, 48, device = device) + 48\n",
    "        crop_index1 = crop_index1.type(torch.long)\n",
    "        x = x.squeeze(dim = 1)\n",
    "        x_extended = torch.cat((x, torch.full_like(x[:, :48], torch.median(x))), dim = -1)\n",
    "        x_extended = torch.cat((torch.full_like(x[:, :48], torch.median(x)), x_extended), dim = 1)\n",
    "        x_cropped = x_extended[torch.arange(x_extended.size(0)).unsqueeze(1), crop_index1]\n",
    "        x_cropped = x_cropped.unsqueeze(dim = 1)\n",
    "        x = x.unsqueeze(dim = 1)\n",
    "\n",
    "        if self.rescale_2 == \"mean\":\n",
    "            x_scale_2 = x_cropped - torch.mean(x_cropped, dim = -1, keepdim = True)\n",
    "        elif self.rescale_2 == \"zscore\":\n",
    "            x_scale_2 = (x_cropped - torch.mean(x_cropped, dim = -1, keepdim = True)) / torch.std(x_cropped, dim = -1, keepdim = True)\n",
    "        else:\n",
    "            x_scale_2 = torch.clone(x_cropped)\n",
    "\n",
    "        x3_1 = self.layer3_1(x_scale_2)\n",
    "        x3_2 = self.layer3_2(x3_1)\n",
    "        x3_flatten = x3_2.view(x3_2.size(0), -1)\n",
    "\n",
    "        x5 = self.layer5(x3_flatten)\n",
    "        x5 = x2_mask * x5\n",
    "\n",
    "        if self.rescale_3 == \"mean\":\n",
    "            x_scale_3 = x_cropped - torch.mean(x_cropped, dim = -1, keepdim = True)\n",
    "        elif self.rescale_3 == \"zscore\":\n",
    "            x_scale_3 = (x_cropped - torch.mean(x_cropped, dim = -1, keepdim = True)) / torch.std(x_cropped, dim = -1, keepdim = True)\n",
    "        else:\n",
    "            x_scale_3 = torch.clone(x_cropped)\n",
    "\n",
    "        x4_1 = self.layer4_1(x_scale_3)\n",
    "        x4_2 = self.layer4_2(x4_1)\n",
    "        x4_flatten = x4_2.view(x4_2.size(0), -1)\n",
    "\n",
    "        x6 = self.layer6(x4_flatten)\n",
    "        x6 = x2_mask * x6\n",
    "\n",
    "        x2 = torch.unsqueeze(x2, dim = 0)\n",
    "        x5 = torch.unsqueeze(x5, dim = 0)\n",
    "        x6 = torch.unsqueeze(x6, dim = 0)\n",
    "\n",
    "        return (torch.cat((x2, x5, x6), 0), x_scale_1, x_cropped, x_scale_2, x_scale_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "thksTRyeMvIG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "spectra_info_test = []\n",
    "with open(\"/pscratch/sd/j/juikuan/DESI_LAE_dataset/train_spectra/fuji_pre_b.pkl\", \"rb\") as fh:\n",
    "    spectra = pickle.load(fh)\n",
    "    spectra_info_test += spectra\n",
    "    fuji = np.array([np.array(i[\"FLUX\"]).reshape(1, -1) for i in spectra]) * np.array([np.array(i[\"IVAR\"]).reshape(1, -1) ** (1 / 2) for i in spectra])\n",
    "    \n",
    "with open(\"/pscratch/sd/j/juikuan/DESI_LAE_dataset/train_label/fuji_pre_25.pkl\", \"rb\") as fh:\n",
    "    fuji_label = pickle.load(fh)\n",
    "    \n",
    "spectra_info_train = []\n",
    "with open(\"/pscratch/sd/j/juikuan/DESI_LAE_dataset/train_spectra/iron_pre_b.pkl\", \"rb\") as fh:\n",
    "    spectra = pickle.load(fh)\n",
    "    spectra_info_train += spectra\n",
    "    iron = np.array([np.array(i[\"FLUX\"]).reshape(1, -1) for i in spectra]) * np.array([np.array(i[\"IVAR\"]).reshape(1, -1) ** (1 / 2) for i in spectra])\n",
    "    \n",
    "with open(\"/pscratch/sd/j/juikuan/DESI_LAE_dataset/train_label/iron_pre_25.pkl\", \"rb\") as fh:\n",
    "    iron_label = pickle.load(fh)\n",
    "    \n",
    "np.random.seed(3)\n",
    "np.random.shuffle(spectra_info)\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(spectra_info_test)\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(fuji)\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(fuji_label)\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(iron)\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(iron_label)\n",
    "\n",
    "x_train = iron\n",
    "y_train = iron_label\n",
    "\n",
    "x_test = fuji\n",
    "y_test = fuji_label\n",
    "\n",
    "x_train_id = ray.put(x_train)\n",
    "y_train_id = ray.put(y_train)\n",
    "x_test_id = ray.put(x_test)\n",
    "y_test_id = ray.put(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kgP3VX3BW1kj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, criterion, train_loader, thres):\n",
    "    train_loss_iter = 0\n",
    "    correct_1 = 0\n",
    "    correct_2 = 0\n",
    "    correct_3 = 0\n",
    "    output1_record = torch.tensor([[], []], device = device)\n",
    "    output2_record = torch.tensor([[], []], device = device)\n",
    "    output3_record = torch.tensor([[], []], device = device)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model = model.to(device).float()\n",
    "        results = model(data.float())\n",
    "        output = results[0]\n",
    "\n",
    "        loss, loss_1, loss_2, loss_3 = criterion(output.float(), target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_iter += loss\n",
    "\n",
    "        output = output.detach()\n",
    "\n",
    "        output1 = output[0].argmax(dim = -1)\n",
    "        output1[output[0].max(dim = -1)[0] < thres] = 0\n",
    "        target1 = target.permute(1, 0, 2)[0].argmax(dim = -1)\n",
    "        difference1 = (output1 - target1) ** 2\n",
    "        correct_1 += len(difference1[difference1 < 1])\n",
    "        output1_record = torch.cat((output1_record, torch.cat((output1.unsqueeze(0), target1.unsqueeze(0)), dim = 0)), dim = -1)\n",
    "\n",
    "        mask1 = torch.where(output[0] > 0.7, 1, 0)\n",
    "\n",
    "        output2 = torch.sum(output[1] * mask1, dim = -1)\n",
    "        target2 = torch.sum((target.permute(1, 0, 2)[1]), dim = -1)\n",
    "        difference2 = (output2 - target2) ** 2\n",
    "        correct_2 += len(difference2[difference2 < 0.0025])\n",
    "        output2_record = torch.cat((output2_record, torch.cat((output2.unsqueeze(0), target2.unsqueeze(0)), dim = 0)), dim = -1)\n",
    "\n",
    "        output3 = torch.sum(output[2] * mask1, dim = -1)\n",
    "        target3 = torch.sum((target.permute(1, 0, 2)[2]), dim = -1)\n",
    "        difference3 = (output3 - target3) ** 2\n",
    "        correct_3 += len(difference3[difference3 < 9])\n",
    "        output3_record = torch.cat((output3_record, torch.cat((output3.unsqueeze(0), target3.unsqueeze(0)), dim = 0)), dim = -1)\n",
    "\n",
    "    train_loss_iter /= len(train_loader.dataset)\n",
    "\n",
    "    return model, train_loss_iter, output1_record, output2_record, output3_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lSJxXfdYfhjl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(epoch, model, criterion, test_loader, ray_tune, thres):\n",
    "    test_loss_iter = 0\n",
    "    test_loss1_iter = 0\n",
    "    test_loss2_iter = 0\n",
    "    test_loss3_iter = 0\n",
    "    correct_1 = 0\n",
    "    correct_2 = 0\n",
    "    correct_3 = 0\n",
    "    output1_record = torch.tensor([[], []], device = device)\n",
    "    output2_record = torch.tensor([[], []], device = device)\n",
    "    output3_record = torch.tensor([[], []], device = device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            model = model.to(device).float()\n",
    "            results = model(data.float())\n",
    "            output = results[0]\n",
    "\n",
    "            loss, loss_1, loss_2, loss_3 = criterion(output.float(), target.float())\n",
    "            test_loss_iter += loss\n",
    "            test_loss1_iter += loss_1\n",
    "            test_loss2_iter += loss_2\n",
    "            test_loss3_iter += loss_3\n",
    "\n",
    "            output1 = output[0].argmax(dim = -1)\n",
    "            output1[output[0].max(dim = -1)[0] < thres] = 0\n",
    "            target1 = target.permute(1, 0, 2)[0].argmax(dim = -1)\n",
    "            difference1 = (output1 - target1) ** 2\n",
    "            correct_1 += len(difference1[difference1 < 1])\n",
    "            output1_record = torch.cat((output1_record, torch.cat((output1.unsqueeze(0), target1.unsqueeze(0)), dim = 0)), dim = -1)\n",
    "\n",
    "            mask1 = torch.where(output[0] > thres, 1, 0)\n",
    "\n",
    "            output2 = torch.sum(output[1] * mask1, dim = -1)\n",
    "            target2 = torch.sum((target.permute(1, 0, 2)[1]), dim = -1)\n",
    "            difference2 = (output2 - target2) ** 2\n",
    "            correct_2 += len(difference2[difference2 < 0.0025])\n",
    "            output2_record = torch.cat((output2_record, torch.cat((output2.unsqueeze(0), target2.unsqueeze(0)), dim = 0)), dim = -1)\n",
    "\n",
    "            output3 = torch.sum(output[2] * mask1, dim = -1)\n",
    "            target3 = torch.sum((target.permute(1, 0, 2)[2]), dim = -1)\n",
    "            difference3 = (output3 - target3) ** 2\n",
    "            correct_3 += len(difference3[difference3 < 9])\n",
    "            output3_record = torch.cat((output3_record, torch.cat((output3.unsqueeze(0), target3.unsqueeze(0)), dim = 0)), dim = -1)\n",
    "\n",
    "    data_count = len(test_loader.dataset)\n",
    "\n",
    "    test_loss_iter /= data_count\n",
    "    test_loss1_iter /= data_count\n",
    "    test_loss2_iter /= data_count\n",
    "    test_loss3_iter /= data_count\n",
    "\n",
    "    if not ray_tune:\n",
    "        print(f'平均損失: {test_loss_iter:.6f}, 1st loss: {test_loss1_iter:.6f}({correct_1 / data_count * 100:.1f}), 2nd loss: {test_loss2_iter:.6f}({correct_2 / data_count * 100:.1f}), 3rd loss: {test_loss3_iter:.6f}({correct_3 / data_count * 100:.1f})')\n",
    "\n",
    "    return model, (test_loss_iter, test_loss1_iter, test_loss2_iter, test_loss3_iter), (correct_1 / data_count, correct_2 / data_count, correct_3 / data_count), output1_record, output2_record, output3_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TqShYOTHJS8u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity = 'relu', mode = 'fan_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-48MBtWOXT66",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(config, x_train_id = x_train_id, y_train_id = y_train_id, x_test_id = x_test_id, y_test_id = y_test_id, ray_tune = True, model_size = \"M\"):\n",
    "    \n",
    "    x = ray.get(x_train_id)\n",
    "    \n",
    "    length = round(config[\"ratio\"] * x.shape[0])\n",
    "    if length % int(config[\"batch\"]) == 1:\n",
    "        random_indices = np.random.randint(x.shape[0], size = length + 1)\n",
    "    else:\n",
    "        random_indices = np.random.randint(x.shape[0], size = length)\n",
    "    \n",
    "    x = x[random_indices]\n",
    "    y = ray.get(y_train_id)\n",
    "    y = y[random_indices]\n",
    "    \n",
    "    train_dataset = CustomDataset(x = x, y = y)\n",
    "    test_dataset = CustomDataset(x = ray.get(x_test_id), y = ray.get(y_test_id))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size = config[\"batch\"], num_workers = 128, pin_memory = True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = config[\"batch\"], num_workers = 128, pin_memory = True)\n",
    "\n",
    "    model = ConvNet(kernel_size1_1 = config[\"ks1_1\"], kernel_size4_2 = config[\"ks4_2\"],\n",
    "                  kernel_size3_1 = config[\"ks3_1\"], thres = config[\"thres\"],\n",
    "                  kernel_size3_2 = config[\"ks3_2\"], kernel_size4_1 = config[\"ks4_1\"],\n",
    "                  ratio = config[\"ks_ratio\"], out_channel7 = config[\"out_ch7\"],\n",
    "                  pooling = config[\"ps\"], fc_width1 = config[\"w1\"],\n",
    "                  fc_width2 = config[\"w2\"], fc_width3 = config[\"w3\"],\n",
    "                  rescale_1 = config[\"rescale1\"], rescale_2 = config[\"rescale2\"],\n",
    "                  rescale_3 = config[\"rescale3\"], factor = config[\"factor\"])\n",
    "\n",
    "    criterion = customLoss(weight = [config[\"lw1\"], config[\"lw2\"], config[\"lw3\"]])\n",
    "    optimizer = optim.Adam(model.parameters(), lr = config[\"lr\"])\n",
    "\n",
    "    epoch = 60\n",
    "\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    for i in range(1, epoch + 1):\n",
    "        model.train()\n",
    "        model, train_loss_iter, output1_record, output2_record, output3_record = train(epoch = i, model = model, criterion = criterion, optimizer = optimizer, train_loader = train_loader, thres = config[\"thres\"])\n",
    "\n",
    "        model.eval()\n",
    "        model, test_loss_iter, test_accuracy_iter, output1_record, output2_record, output3_record = test(epoch = i, model = model, criterion = criterion, test_loader = test_loader, ray_tune = ray_tune, thres = config[\"thres\"])\n",
    "\n",
    "        ray.train.report({\"acc1\": test_acc_1[-1], \"acc2\": test_acc_2[-1], \"acc3\": test_acc_3[-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_iter(test_loss, train_loss):\n",
    "    plt.close()\n",
    "    epoch = [i for i in range(1, len(test_loss) + 1)]\n",
    "    plt.plot(epoch, test_loss, label = \"Test Loss\", c = \"m\")\n",
    "    plt.plot(epoch, train_loss, label = \"Train Loss\", c = \"y\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    # plt.savefig(\"/content/drive/MyDrive/loss.jpg\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_test_accuracy(test_acc1, test_acc2, test_acc3):\n",
    "    plt.close()\n",
    "    epoch = [i for i in range(1, len(test_acc1) + 1)]\n",
    "    plt.plot(epoch, test_acc1, label = \"Rough Position\", c = \"r\")\n",
    "    plt.plot(epoch, test_acc2, label = \"Precise Position\", c = \"m\")\n",
    "    plt.plot(epoch, test_acc3, label = \"FWHM\", c = \"y\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    # plt.savefig(\"/content/drive/MyDrive/loss.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zaNyGbs-JG2",
    "outputId": "5dbdd51d-fdd8-4b6a-fe1c-917eb2151600",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": tune.choice([0.005368]),\n",
    "    \"ks1_1\": tune.qrandint(9, 45, 2),\n",
    "    \"ks3_1\": tune.choice([3]),\n",
    "    \"ks3_2\": tune.choice([3]),\n",
    "    \"ks4_1\": tune.choice([3]),\n",
    "    \"ks4_2\": tune.choice([3]),\n",
    "    \"batch\": tune.choice([8]),\n",
    "    \"ks_ratio\": tune.loguniform(0.1, 10),\n",
    "    \"out_ch7\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"ps\": tune.choice([3]),\n",
    "    \"lw1\": tune.choice([1]),\n",
    "    \"lw2\": tune.choice([1 / 5]),\n",
    "    \"lw3\": tune.choice([1 / 2 * 10 ** -2]),\n",
    "    \"w1\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"w2\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"w3\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"rescale1\": tune.choice([\"mean\"]),\n",
    "    \"rescale2\": tune.choice([\"mean\"]),\n",
    "    \"rescale3\": tune.choice([\"mean\"]),\n",
    "    \"LAE_w\": tune.choice([False]),\n",
    "    \"ratio\": tune.choice([1]),\n",
    "    \"thres\": tune.uniform(0.5, 1),\n",
    "    \"factor\": tune.loguniform(0.1, 10)\n",
    "}\n",
    "\n",
    "optuna_search = OptunaSearch(\n",
    "    metric = \"acc1\",\n",
    ")\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric = \"acc1\",\n",
    "    max_t = 100,\n",
    "    grace_period=10,\n",
    "    reduction_factor = 2\n",
    ")\n",
    "\n",
    "trainable_with_gpu = tune.with_resources(build_model, {\"gpu\": 1})\n",
    "analysis = tune.run(\n",
    "    trainable_with_gpu,\n",
    "    search_alg = optuna_search,\n",
    "    scheduler = scheduler,\n",
    "    num_samples = 400,\n",
    "    mode = \"max\",\n",
    "    config = search_space,\n",
    "    reuse_actors = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": tune.grid_search([0.005368]),\n",
    "    \"ks1_1\": tune.grid_search([13]),\n",
    "    \"ks3_1\": tune.grid_search([3]),\n",
    "    \"ks3_2\": tune.grid_search([3]),\n",
    "    \"ks4_1\": tune.grid_search([3]),\n",
    "    \"ks4_2\": tune.grid_search([3]),\n",
    "    \"batch\": tune.grid_search([8]),\n",
    "    \"ks_ratio\": tune.grid_search([1.324924256]),\n",
    "    \"out_ch7\": tune.grid_search([512]),\n",
    "    \"ps\": tune.grid_search([3]),\n",
    "    \"lw1\": tune.grid_search([1]),\n",
    "    \"lw2\": tune.grid_search([1 / 5]),\n",
    "    \"lw3\": tune.grid_search([1 / 2 * 10 ** -2]),\n",
    "    \"w1\": tune.grid_search([32]),\n",
    "    \"w2\": tune.grid_search([128]),\n",
    "    \"w3\": tune.grid_search([512]),\n",
    "    \"rescale1\": tune.grid_search([\"mean\"]),\n",
    "    \"rescale2\": tune.grid_search([\"mean\"]),\n",
    "    \"rescale3\": tune.grid_search([\"mean\"]),\n",
    "    \"LAE_w\": tune.grid_search([False]),\n",
    "    \"ratio\": tune.grid_search([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]),\n",
    "    \"thres\": tune.grid_search([0.554768217]),\n",
    "    \"factor\": tune.grid_search([6.755653316])\n",
    "}\n",
    "\n",
    "trainable_with_gpu = tune.with_resources(build_model, {\"gpu\": 1})\n",
    "tuner = tune.Tuner(\n",
    "    trainable_with_gpu,\n",
    "    param_space = search_space,\n",
    "    tune_config = tune.TuneConfig(num_samples = 8)\n",
    ")\n",
    "results = tuner.fit()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
