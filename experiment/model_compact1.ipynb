{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "rpYGw1etWG8s",
    "outputId": "ad14e6e2-e5e8-4715-f01d-710e2d177372",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ray\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import optuna\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "5sA9GgKwWWMM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, x, y, target_transform = False):\n",
    "    self.labels = y\n",
    "    self.spectrum = x\n",
    "    self.target_transform = target_transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    spectra = self.spectrum[idx]\n",
    "    label = self.labels[idx]\n",
    "\n",
    "    if self.target_transform != False:\n",
    "      label = self.target_transform(label)\n",
    "    else:\n",
    "      pass\n",
    "\n",
    "    return torch.tensor(spectra), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3ZgxYDifiI-r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "  def __init__(self, weight = [1, 1, 1], punish_distance = False, punish_Lya = False):\n",
    "    super(customLoss, self).__init__()\n",
    "    self.weight = weight\n",
    "    self.punish_distance = punish_distance\n",
    "    self.punish_Lya = punish_Lya\n",
    "\n",
    "  def forward(self, output, target):\n",
    "    weight = self.weight\n",
    "    target = target.permute(1, 0, 2)\n",
    "\n",
    "    if self.punish_distance == True:\n",
    "      punish = (torch.abs(torch.argmax(output[0], dim = 1) - torch.argmax(target[0], dim = 1)) * torch.sum(target[0], dim = 1) + (output[0] > 0.1).sum(dim = 1) * (1 - torch.sum(target[0], dim = 1)))\n",
    "      punish = (punish / max(torch.sum(punish).item(), 1) * 64).unsqueeze(dim = 1).tile(1, 78)\n",
    "      BCE = nn.BCELoss(reduction = \"mean\", weight = punish)\n",
    "    elif self.punish_Lya != False:\n",
    "      punish = torch.where(torch.sum(target[0], dim = -1) > 0, self.punish_Lya, 1)\n",
    "      punish = ((punish / torch.sum(punish).item()) * 64).unsqueeze(dim = -1).tile(1, 78)\n",
    "      BCE = nn.BCELoss(reduction = \"mean\", weight = punish)\n",
    "    else:\n",
    "      BCE = nn.BCELoss(reduction = \"mean\")\n",
    "\n",
    "    MSE = nn.MSELoss(reduction = \"mean\")\n",
    "    loss_1 = BCE(output[0], target[0])\n",
    "    loss_2 = BCE(output[1], target[1])\n",
    "    loss_3 = MSE(output[2], target[2])\n",
    "\n",
    "    loss_total = weight[0] * loss_1 + weight[1] * loss_2 + weight[2] * loss_3\n",
    "\n",
    "    return loss_total / sum(weight), loss_1, loss_2, loss_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "XkfeAzs3BCdB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, kernel_size1_1, kernel_size3_1, kernel_size3_2, kernel_size4_1, kernel_size4_2, ratio, out_channel4, pooling, fc_width1, fc_width2, fc_width3, rescale_1, rescale_2, rescale_3, thres):\n",
    "        self.rescale_1 = rescale_1\n",
    "        self.rescale_2 = rescale_2\n",
    "        self.rescale_3 = rescale_3\n",
    "        self.thres = thres\n",
    "\n",
    "        super(ConvNet, self).__init__()\n",
    "        if round(kernel_size1_1 * ratio) % 2 == 0:\n",
    "            kernel_size1_2 = round(kernel_size1_1 * ratio) + 1\n",
    "        else:\n",
    "            kernel_size1_2 = round(kernel_size1_1 * ratio)\n",
    "        stride = 1\n",
    "        padding3_1 = kernel_size3_1 // 2\n",
    "        padding3_2 = kernel_size3_2 // 2\n",
    "        padding4_1 = kernel_size4_1 // 2\n",
    "        padding4_2 = kernel_size4_2 // 2\n",
    "        dilation = 1\n",
    "        factor = 2\n",
    "        out_channel = 10 * factor\n",
    "        out_channel2 = 10 * factor\n",
    "        out_channel3 = 20 * factor\n",
    "\n",
    "        self.layer1_1 = nn.Sequential(\n",
    "            nn.Conv1d(1, out_channel, kernel_size = kernel_size1_1, stride = stride, padding = kernel_size1_1 // 2, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer1_2 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel, out_channel2, kernel_size = kernel_size1_2, stride = stride, padding = kernel_size1_2 // 2, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size = pooling, stride = pooling - 1, padding = pooling // 2),\n",
    "            )\n",
    "        self.layer1_3 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel2, out_channel3, kernel_size = 1, stride = stride, padding = 0, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel3),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer1_4 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel3, out_channel4, kernel_size = 1, stride = stride, padding = 0, dilation = dilation),\n",
    "            )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(1219 * out_channel4, fc_width1),\n",
    "            nn.BatchNorm1d(fc_width1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width1, 78),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        self.layer3_1 = nn.Sequential(\n",
    "            nn.Conv1d(1, out_channel, kernel_size = kernel_size3_1, stride = stride, padding = padding3_1, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer3_2 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel, out_channel2, kernel_size = kernel_size3_2, stride = stride, padding = padding3_2, dilation = dilation),\n",
    "            )\n",
    "\n",
    "        self.layer4_1 = nn.Sequential(\n",
    "            nn.Conv1d(1, out_channel, kernel_size = 3, stride = stride, padding = 1, dilation = dilation),\n",
    "            nn.BatchNorm1d(out_channel),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.layer4_2 = nn.Sequential(\n",
    "            nn.Conv1d(out_channel, out_channel2, kernel_size = 3, stride = stride, padding = 1, dilation = dilation),\n",
    "            )\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(1900, fc_width2),\n",
    "            nn.BatchNorm1d(fc_width2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width2, 1),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Linear(1900, fc_width3),\n",
    "            nn.BatchNorm1d(fc_width3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_width3, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.rescale_1 == \"mean\":\n",
    "            x_scale_1 = x - torch.mean(x, dim = -1, keepdim = True)\n",
    "        elif self.rescale_1 == \"zscore\":\n",
    "            x_scale_1 = (x - torch.mean(x, dim = -1, keepdim = True)) / torch.std(x, dim = -1, keepdim = True)\n",
    "        else:\n",
    "            x_scale_1 = torch.clone(x)\n",
    "\n",
    "        x1_1 = self.layer1_1(x_scale_1)\n",
    "        x1_2 = self.layer1_2(x1_1)\n",
    "        x1_3 = self.layer1_3(x1_2)\n",
    "        x1_4 = self.layer1_4(x1_3)\n",
    "        x1_flatten = x1_4.view(x1_4.size(0), -1)\n",
    "        x2 = self.layer2(x1_flatten)\n",
    "        x2_mask = torch.zeros_like(x2).to(device)\n",
    "        x2_mask[x2 > self.thres] = 1\n",
    "\n",
    "        crop_index1 = torch.round(torch.argmax(x2, dim = -1) * 31.25 + 15.625).unsqueeze(1) + torch.arange(-47, 48).to(device) + 48\n",
    "        crop_index1 = crop_index1.type(torch.long).to(device)\n",
    "        x = x.squeeze(dim = 1)\n",
    "        x_extended = torch.cat((x, torch.full_like(x[:, :48], torch.median(x)).to(device)), dim = -1)\n",
    "        x_extended = torch.cat((torch.full_like(x[:, :48], torch.median(x)).to(device), x_extended), dim = 1)\n",
    "        x_cropped = x_extended[torch.arange(x_extended.size(0)).unsqueeze(1).to(device), crop_index1]\n",
    "        x_cropped = x_cropped.unsqueeze(dim = 1)\n",
    "        x = x.unsqueeze(dim = 1)\n",
    "\n",
    "        if self.rescale_2 == \"mean\":\n",
    "            x_scale_2 = x_cropped - torch.mean(x_cropped, dim = -1, keepdim = True)\n",
    "        elif self.rescale_2 == \"zscore\":\n",
    "            x_scale_2 = (x_cropped - torch.mean(x_cropped, dim = -1, keepdim = True)) / torch.std(x_cropped, dim = -1, keepdim = True)\n",
    "        else:\n",
    "            x_scale_2 = torch.clone(x_cropped)\n",
    "\n",
    "        x3_1 = self.layer3_1(x_scale_2)\n",
    "        x3_2 = self.layer3_2(x3_1)\n",
    "        x3_flatten = x3_2.view(x3_2.size(0), -1)\n",
    "\n",
    "        x5 = self.layer5(x3_flatten)\n",
    "        crop_index2 = torch.round(torch.sum(x5, dim = -1) * x_cropped.size(-1)).unsqueeze(1) + torch.arange(-22, 23).to(device) + 23\n",
    "        x5 = x2_mask * x5\n",
    "\n",
    "        if self.rescale_3 == \"mean\":\n",
    "            x_scale_3 = x_cropped - torch.mean(x_cropped, dim = -1, keepdim = True)\n",
    "        elif self.rescale_3 == \"zscore\":\n",
    "            x_scale_3 = (x_cropped - torch.mean(x_cropped, dim = -1, keepdim = True)) / torch.std(x_cropped, dim = -1, keepdim = True)\n",
    "        else:\n",
    "            x_scale_3 = torch.clone(x_cropped)\n",
    "\n",
    "        x4_1 = self.layer4_1(x_scale_3)\n",
    "        x4_2 = self.layer4_2(x4_1)\n",
    "        x4_flatten = x4_2.view(x4_2.size(0), -1)\n",
    "\n",
    "        x6 = self.layer6(x4_flatten)\n",
    "        x6 = x2_mask * x6\n",
    "\n",
    "        x2 = torch.unsqueeze(x2, dim = 0)\n",
    "        x5 = torch.unsqueeze(x5, dim = 0)\n",
    "        x6 = torch.unsqueeze(x6, dim = 0)\n",
    "\n",
    "        return torch.cat((x2, x5, x6), 0), x_scale_1, x_cropped, x_scale_2, x_scale_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "thksTRyeMvIG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "spectra_info = []\n",
    "with open(\"/pscratch/sd/j/juikuan/DESI_LAE_dataset/train_spectra/fuji_pre_b.pkl\", \"rb\") as fh:\n",
    "    spectra = pickle.load(fh)\n",
    "    spectra_info += spectra\n",
    "    fuji = np.array([np.array(i[\"FLUX\"]).reshape(1, -1) for i in spectra]) * np.array([np.array(i[\"IVAR\"]).reshape(1, -1) ** (1 / 2) for i in spectra])\n",
    "    \n",
    "with open(\"/pscratch/sd/j/juikuan/DESI_LAE_dataset/train_label/fuji_pre_25.pkl\", \"rb\") as fh:\n",
    "    fuji_label = pickle.load(fh)\n",
    "    \n",
    "spectra_info_test = []\n",
    "with open(\"/pscratch/sd/j/juikuan/DESI_LAE_dataset/train_spectra/iron_pre_b.pkl\", \"rb\") as fh:\n",
    "    spectra = pickle.load(fh)\n",
    "    spectra_info_test += spectra\n",
    "    iron = np.array([np.array(i[\"FLUX\"]).reshape(1, -1) for i in spectra]) * np.array([np.array(i[\"IVAR\"]).reshape(1, -1) ** (1 / 2) for i in spectra])\n",
    "    \n",
    "with open(\"/pscratch/sd/j/juikuan/DESI_LAE_dataset/train_label/iron_pre_25.pkl\", \"rb\") as fh:\n",
    "    iron_label = pickle.load(fh)\n",
    "    \n",
    "np.random.seed(3)\n",
    "np.random.shuffle(spectra_info)\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(spectra_info_test)\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(fuji)\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(fuji_label)\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(iron)\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(iron_label)\n",
    "\n",
    "x_train = iron\n",
    "y_train = iron_label\n",
    "\n",
    "x_test = fuji\n",
    "y_test = fuji_label\n",
    "\n",
    "x_train_id = ray.put(x_train)\n",
    "y_train_id = ray.put(y_train)\n",
    "x_test_id = ray.put(x_test)\n",
    "y_test_id = ray.put(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "kgP3VX3BW1kj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, criterion, train_loader, thres):\n",
    "    train_loss_iter = 0\n",
    "    correct_1 = 0\n",
    "    correct_2 = 0\n",
    "    correct_3 = 0\n",
    "    output1_record = torch.tensor([[], []])\n",
    "    output2_record = torch.tensor([[], []])\n",
    "    output3_record = torch.tensor([[], []])\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model = model.to(device).float()\n",
    "        results = model(data.float())\n",
    "        output = results[0]\n",
    "\n",
    "        loss, loss_1, loss_2, loss_3 = criterion(output.float(), target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_iter += loss\n",
    "\n",
    "        output = output.detach()\n",
    "\n",
    "        output1 = output[0].argmax(dim = -1)\n",
    "        output1[output[0].max(dim = -1)[0] < thres] = 0\n",
    "        target1 = target.permute(1, 0, 2)[0].argmax(dim = -1)\n",
    "        difference1 = (output1 - target1) ** 2\n",
    "        correct_1 += len(difference1[difference1 < 1])\n",
    "        output1_record = torch.cat((output1_record.to(\"cpu\"), torch.cat((output1.unsqueeze(0).to(\"cpu\"), target1.unsqueeze(0).to(\"cpu\")), dim = 0)), dim = -1)\n",
    "\n",
    "        mask1 = torch.where(output[0] > 0.7, 1, 0)\n",
    "\n",
    "        output2 = torch.sum(output[1] * mask1, dim = -1)\n",
    "        target2 = torch.sum((target.permute(1, 0, 2)[1]), dim = -1)\n",
    "        difference2 = (output2 - target2) ** 2\n",
    "        correct_2 += len(difference2[difference2 < 0.0025])\n",
    "        output2_record = torch.cat((output2_record.to(\"cpu\"), torch.cat((output2.unsqueeze(0).to(\"cpu\"), target2.unsqueeze(0).to(\"cpu\")), dim = 0)), dim = -1)\n",
    "\n",
    "        output3 = torch.sum(output[2] * mask1, dim = -1)\n",
    "        target3 = torch.sum((target.permute(1, 0, 2)[2]), dim = -1)\n",
    "        difference3 = (output3 - target3) ** 2\n",
    "        correct_3 += len(difference3[difference3 < 9])\n",
    "        output3_record = torch.cat((output3_record.to(\"cpu\"), torch.cat((output3.unsqueeze(0).to(\"cpu\"), target3.unsqueeze(0).to(\"cpu\")), dim = 0)), dim = -1)\n",
    "\n",
    "    train_loss_iter /= len(train_loader.dataset)\n",
    "\n",
    "    return model, train_loss_iter, output1_record, output2_record, output3_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lSJxXfdYfhjl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(epoch, model, criterion, test_loader, ray_tune, thres):\n",
    "    test_loss_iter = 0\n",
    "    test_loss1_iter = 0\n",
    "    test_loss2_iter = 0\n",
    "    test_loss3_iter = 0\n",
    "    correct_1 = 0\n",
    "    correct_2 = 0\n",
    "    correct_3 = 0\n",
    "    output1_record = torch.tensor([[], []])\n",
    "    output2_record = torch.tensor([[], []])\n",
    "    output3_record = torch.tensor([[], []])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            model = model.to(device).float()\n",
    "            results = model(data.float())\n",
    "            output = results[0]\n",
    "\n",
    "            loss, loss_1, loss_2, loss_3 = criterion(output.float(), target.float())\n",
    "            test_loss_iter += loss\n",
    "            test_loss1_iter += loss_1\n",
    "            test_loss2_iter += loss_2\n",
    "            test_loss3_iter += loss_3\n",
    "\n",
    "            output1 = output[0].argmax(dim = -1)\n",
    "            output1[output[0].max(dim = -1)[0] < thres] = 0\n",
    "            target1 = target.permute(1, 0, 2)[0].argmax(dim = -1)\n",
    "            difference1 = (output1 - target1) ** 2\n",
    "            correct_1 += len(difference1[difference1 < 1])\n",
    "            output1_record = torch.cat((output1_record.to(\"cpu\"), torch.cat((output1.unsqueeze(0).to(\"cpu\"), target1.unsqueeze(0).to(\"cpu\")), dim = 0)), dim = -1)\n",
    "\n",
    "            mask1 = torch.where(output[0] > 0.7, 1, 0)\n",
    "\n",
    "            output2 = torch.sum(output[1] * mask1, dim = -1)\n",
    "            target2 = torch.sum((target.permute(1, 0, 2)[1]), dim = -1)\n",
    "            difference2 = (output2 - target2) ** 2\n",
    "            correct_2 += len(difference2[difference2 < 0.0025])\n",
    "            output2_record = torch.cat((output2_record.to(\"cpu\"), torch.cat((output2.unsqueeze(0).to(\"cpu\"), target2.unsqueeze(0).to(\"cpu\")), dim = 0)), dim = -1)\n",
    "\n",
    "            output3 = torch.sum(output[2] * mask1, dim = -1)\n",
    "            target3 = torch.sum((target.permute(1, 0, 2)[2]), dim = -1)\n",
    "            difference3 = (output3 - target3) ** 2\n",
    "            correct_3 += len(difference3[difference3 < 9])\n",
    "            output3_record = torch.cat((output3_record.to(\"cpu\"), torch.cat((output3.unsqueeze(0).to(\"cpu\"), target3.unsqueeze(0).to(\"cpu\")), dim = 0)), dim = -1)\n",
    "\n",
    "    data_count = len(test_loader.dataset)\n",
    "\n",
    "    test_loss_iter /= data_count\n",
    "    test_loss1_iter /= data_count\n",
    "    test_loss2_iter /= data_count\n",
    "    test_loss3_iter /= data_count\n",
    "\n",
    "    if not ray_tune:\n",
    "        print(f'平均損失: {test_loss_iter:.6f}, 1st loss: {test_loss1_iter:.6f}({correct_1 / data_count * 100:.1f}), 2nd loss: {test_loss2_iter:.6f}({correct_2 / data_count * 100:.1f}), 3rd loss: {test_loss3_iter:.6f}({correct_3 / data_count * 100:.1f})')\n",
    "\n",
    "    return model, (test_loss_iter, test_loss1_iter, test_loss2_iter, test_loss3_iter), (correct_1 / data_count, correct_2 / data_count, correct_3 / data_count), output1_record, output2_record, output3_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "TqShYOTHJS8u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity = 'relu', mode = 'fan_in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-48MBtWOXT66",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(config, x_train_id = x_train_id, y_train_id = y_train_id, x_test_id = x_test_id, y_test_id = y_test_id, ray_tune = True, model_size = \"M\"):\n",
    "    train_loss = []\n",
    "    output1_record_train = []\n",
    "    output2_record_train = []\n",
    "    output3_record_train = []\n",
    "    \n",
    "    test_loss = []\n",
    "    test_loss_1 = []\n",
    "    test_loss_2 = []\n",
    "    test_loss_3 = []\n",
    "    test_acc_1 = []\n",
    "    test_acc_2 = []\n",
    "    test_acc_3 = []\n",
    "    output1_record_test = []\n",
    "    output2_record_test = []\n",
    "    output3_record_test = []\n",
    "    \n",
    "    x = ray.get(x_train_id)\n",
    "    random_indices = np.random.randint(x.shape[0], size=round(config[\"ratio\"] * x.shape[0]))\n",
    "    x = x[random_indices]\n",
    "    \n",
    "    y = ray.get(y_train_id)\n",
    "    y = y[random_indices]\n",
    "    \n",
    "    train_dataset = CustomDataset(x = x, y = y)\n",
    "    test_dataset = CustomDataset(x = ray.get(x_test_id), y = ray.get(y_test_id))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size = config[\"batch\"])\n",
    "    test_loader = DataLoader(test_dataset, batch_size = config[\"batch\"])\n",
    "\n",
    "    model = ConvNet(kernel_size1_1 = config[\"ks1_1\"], kernel_size4_2 = config[\"ks4_2\"],\n",
    "                  kernel_size3_1 = config[\"ks3_1\"],\n",
    "                  kernel_size3_2 = config[\"ks3_2\"], kernel_size4_1 = config[\"ks4_1\"],\n",
    "                  ratio = config[\"ks_ratio\"], out_channel4 = config[\"out_ch4\"],\n",
    "                  pooling = config[\"ps\"], fc_width1 = config[\"w1\"],\n",
    "                  fc_width2 = config[\"w2\"], fc_width3 = config[\"w3\"],\n",
    "                  rescale_1 = config[\"rescale1\"], rescale_2 = config[\"rescale2\"],\n",
    "                  rescale_3 = config[\"rescale3\"], thres = config[\"thres\"])\n",
    "\n",
    "    criterion = customLoss(weight = [config[\"lw1\"], config[\"lw2\"], config[\"lw3\"]])\n",
    "    optimizer = optim.Adam(model.parameters(), lr = config[\"lr\"])\n",
    "\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    epoch = 60\n",
    "    \n",
    "    for i in range(1, epoch + 1):\n",
    "        model.train()\n",
    "        model, train_loss_iter, output1_record, output2_record, output3_record = train(epoch = i, model = model, criterion = criterion, optimizer = optimizer, train_loader = train_loader, thres = config[\"thres\"])\n",
    "        train_loss.append(train_loss_iter)\n",
    "        output1_record_train.append(output1_record)\n",
    "        output2_record_train.append(output2_record)\n",
    "        output3_record_train.append(output3_record)\n",
    "\n",
    "        model.eval()\n",
    "        model, test_loss_iter, test_accuracy_iter, output1_record, output2_record, output3_record = test(epoch = i, model = model, criterion = criterion, test_loader = test_loader, ray_tune = ray_tune, thres = config[\"thres\"])\n",
    "        test_loss.append(test_loss_iter[0])\n",
    "        test_loss_1.append(test_loss_iter[1])\n",
    "        test_loss_2.append(test_loss_iter[2])\n",
    "        test_loss_3.append(test_loss_iter[3])\n",
    "        test_acc_1.append(test_accuracy_iter[0])\n",
    "        test_acc_2.append(test_accuracy_iter[1])\n",
    "        test_acc_3.append(test_accuracy_iter[2])\n",
    "        output1_record_test.append(output1_record)\n",
    "        output2_record_test.append(output2_record)\n",
    "        output3_record_test.append(output3_record)\n",
    "\n",
    "        if ray_tune:\n",
    "            ray.train.report({\"acc1\": test_acc_1[test_loss.index(min(test_loss))], \"acc2\": test_acc_2[test_loss.index(min(test_loss))], \"loss\": test_loss[-1].item()})\n",
    "        else:\n",
    "            if test_acc_1[-1] > 0.895:\n",
    "                current_time = datetime.datetime.now()\n",
    "                torch.save(model, f\"/pscratch/sd/j/juikuan/DESI_LAE_model/model_compact1_{test_acc_1[-1]:.3f}_{test_acc_2[-1]:.3f}_{test_acc_3[-1]:.3f}_{current_time}.pt\")\n",
    "                print(\"Saved!\")\n",
    "                \n",
    "    if not ray_tune:\n",
    "        return model, train_loss, test_loss, test_acc_1, test_acc_2, test_acc_3, output1_record_train, output2_record_train, output3_record_train, output1_record_test, output2_record_test, output3_record_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_iter(test_loss, train_loss):\n",
    "    plt.close()\n",
    "    epoch = [i for i in range(1, len(test_loss) + 1)]\n",
    "    plt.plot(epoch, test_loss, label = \"Test Loss\", c = \"m\")\n",
    "    plt.plot(epoch, train_loss, label = \"Train Loss\", c = \"y\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    # plt.savefig(\"/content/drive/MyDrive/loss.jpg\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_test_accuracy(test_acc1, test_acc2, test_acc3):\n",
    "    plt.close()\n",
    "    epoch = [i for i in range(1, len(test_acc1) + 1)]\n",
    "    plt.plot(epoch, test_acc1, label = \"Rough Position\", c = \"r\")\n",
    "    plt.plot(epoch, test_acc2, label = \"Precise Position\", c = \"m\")\n",
    "    plt.plot(epoch, test_acc3, label = \"FWHM\", c = \"y\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    # plt.savefig(\"/content/drive/MyDrive/loss.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zaNyGbs-JG2",
    "outputId": "5dbdd51d-fdd8-4b6a-fe1c-917eb2151600",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": tune.choice([0.005368]),\n",
    "    \"ks1_1\": tune.qrandint(9, 45, 2),\n",
    "    \"ks3_1\": tune.choice([3]),\n",
    "    \"ks3_2\": tune.choice([3]),\n",
    "    \"ks4_1\": tune.choice([3]),\n",
    "    \"ks4_2\": tune.choice([3]),\n",
    "    \"batch\": tune.choice([8]),\n",
    "    \"ks_ratio\": tune.uniform(0.4, 2),\n",
    "    \"out_ch4\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"ps\": tune.choice([3]),\n",
    "    \"lw1\": tune.choice([1]),\n",
    "    \"lw2\": tune.choice([1 / 5]),\n",
    "    \"lw3\": tune.choice([1 / 2 * 10 ** -2]),\n",
    "    \"w1\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"w2\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"w3\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"rescale1\": tune.choice([\"mean\"]),\n",
    "    \"rescale2\": tune.choice([\"mean\"]),\n",
    "    \"rescale3\": tune.choice([\"mean\"]),\n",
    "    \"LAE_w\": tune.choice([False]),\n",
    "    \"ratio\": tune.choice([1]),\n",
    "    \"thres\": tune.uniform(0.5, 1),\n",
    "    \"factor\": tune.uniform(0.4, 4)\n",
    "}\n",
    "\n",
    "optuna_search = OptunaSearch(\n",
    "    metric = \"acc1\",\n",
    ")\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric = \"acc1\",\n",
    "    max_t = 100,\n",
    "    grace_period=10,\n",
    "    reduction_factor = 2\n",
    ")\n",
    "\n",
    "trainable_with_gpu = tune.with_resources(build_model, {\"gpu\": 1})\n",
    "analysis = tune.run(\n",
    "    trainable_with_gpu,\n",
    "    search_alg = optuna_search,\n",
    "    scheduler = scheduler,\n",
    "    num_samples = 300,\n",
    "    mode = \"max\",\n",
    "    config = search_space,\n",
    "    reuse_actors = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": tune.grid_search([0.005368]),\n",
    "    \"ks1_1\": tune.qrandint(11, 45, 2),\n",
    "    \"ks3_1\": tune.grid_search([3]),\n",
    "    \"ks3_2\": tune.grid_search([3]),\n",
    "    \"ks4_1\": tune.grid_search([3]),\n",
    "    \"ks4_2\": tune.grid_search([3]),\n",
    "    \"batch\": tune.grid_search([8]),\n",
    "    \"ks_ratio\": tune.uniform(0.3, 3),\n",
    "    \"out_ch4\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"ps\": tune.grid_search([3]),\n",
    "    \"lw1\": tune.grid_search([1]),\n",
    "    \"lw2\": tune.grid_search([1 / 5]),\n",
    "    \"lw3\": tune.grid_search([1 / 2 * 10 ** -2]),\n",
    "    \"w1\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"w2\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"w3\": tune.choice([8, 16, 32, 64, 128, 256, 512, 1024]),\n",
    "    \"rescale1\": tune.grid_search([\"mean\"]),\n",
    "    \"rescale2\": tune.grid_search([\"mean\"]),\n",
    "    \"rescale3\": tune.grid_search([\"mean\"]),\n",
    "    \"LAE_w\": tune.grid_search([False]),\n",
    "    \"ratio\": tune.grid_search([1]),\n",
    "    \"thres\": tune.uniform(0.5, 1),\n",
    "    \"factor\": tune.uniform(0.5, 4)\n",
    "}\n",
    "\n",
    "trainable_with_gpu = tune.with_resources(build_model, {\"gpu\": 1})\n",
    "tuner = tune.Tuner(\n",
    "    trainable_with_gpu,\n",
    "    param_space = search_space,\n",
    "    tune_config = tune.TuneConfig(num_samples = 300)\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3jJJoFl5cak5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_perform(model, spectra, label, spectra_info, plot_wrong = False):\n",
    "    with torch.no_grad():\n",
    "        data = torch.tensor(spectra).to(device).float()\n",
    "        model = model.to(device).float()\n",
    "        output, x_scale_1, x_cropped, x_scale_2, x_scale_3 = model(data)\n",
    "        output = output.to(\"cpu\")\n",
    "\n",
    "    print(output.shape)\n",
    "    mask1 = torch.where(output[0] > 0.554768217, 1, 0)\n",
    "    a = torch.argmax(mask1, axis = -1)\n",
    "    \n",
    "    b = torch.argmax(torch.tensor(label).permute(1, 0, 2)[0], axis = -1)\n",
    "    diff = torch.argwhere(a - b).squeeze(dim = -1)\n",
    "    \n",
    "    current_time = datetime.datetime.now()\n",
    "\n",
    "    x_range = spectra_info[0][\"WAVE\"]\n",
    "    pixel_range = np.array([i * 25 + 3600 for i in range(0, 78)])\n",
    "    \n",
    "    plt.close()\n",
    "    plt.rcParams['figure.figsize'] = [15, 5]\n",
    "    plt.figure(dpi = 200)\n",
    "    plt.subplot(131)\n",
    "    plt.scatter(x = a, y = b, c = \"m\", s = 5)\n",
    "    plt.xlabel(xlabel = \"Predicted Position\")\n",
    "    plt.ylabel(ylabel = \"True Position\")\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.scatter(x = torch.sum(mask1 * output[1], dim = -1), y = torch.sum(torch.tensor(label).permute(1, 0, 2)[1], axis = -1), c = \"m\", s = 5)\n",
    "    plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100) - 0.05, c = \"k\")\n",
    "    plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100) + 0.05, c = \"k\")\n",
    "    plt.xlabel(xlabel = \"Predicted Percentage\")\n",
    "    plt.ylabel(ylabel = \"True Percentage\")\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.scatter(x = torch.sum(mask1 * output[2], dim = -1), y = torch.sum(torch.tensor(label).permute(1, 0, 2)[2], axis = -1), c = \"m\", s = 5)\n",
    "    plt.plot(np.linspace(0, 40, 100), np.linspace(0, 40, 100) - 3, c = \"k\")\n",
    "    plt.plot(np.linspace(0, 40, 100), np.linspace(0, 40, 100) + 3, c = \"k\")\n",
    "    plt.xlabel(xlabel = \"Predicted Width (pixel)\")\n",
    "    plt.ylabel(ylabel = \"True Width (pixel)\")\n",
    "    \n",
    "    plt.savefig(f\"/pscratch/sd/j/juikuan/DESI_LAE_diagram/scatter_{current_time}.jpg\", bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    for i in diff:\n",
    "        print(\"=======================================================================================================================\")\n",
    "        if (a[i].item() == 0) & (b[i].item() != 0):\n",
    "            print(\"Ignored LAE.\")\n",
    "        elif (a[i].item() != 0) & (b[i].item() == 0):\n",
    "            print(\"NLAE detected.\")\n",
    "        elif (a[i] - b[i]).item() ** 2 == 1:\n",
    "            print(\"Nearby offset.\")\n",
    "        elif (a[i] - b[i]).item() ** 2 > 1:\n",
    "            print(\"Offset.\")\n",
    "        print(f\"Prediction: {a[i].item()}\")\n",
    "        print(f\"True: {b[i].item()}\")\n",
    "        print(output[0][i])\n",
    "        print(torch.tensor(label).permute(1, 0, 2)[0][i])\n",
    "        \n",
    "        if plot_wrong:\n",
    "            plt.close()\n",
    "            plt.rcParams['figure.figsize'] = [16, 4]\n",
    "            plt.plot(x_range, x_scale_1[i][0].to(\"cpu\"), alpha = 1, c = \"r\", lw = 1)\n",
    "            plt.bar(pixel_range, output[0][i].to(\"cpu\") * torch.max(x_scale_1[i][0].to(\"cpu\")).item(), width = 25, align = \"edge\")\n",
    "            plt.title(str(spectra_info[i]['TARGETID']))\n",
    "            print(str(spectra_info[i]['TARGETID']))\n",
    "            # plt.savefig(\"/content/drive/MyDrive/CNN/result/x_scale_3/\" + str(spectra_info[i]['specid']) + \".jpg\", bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "    plt.close()\n",
    "    cm = confusion_matrix(y_pred = torch.max(mask1, dim = -1)[0], y_true = torch.sum(torch.tensor(label).permute(1, 0, 2)[0], dim = -1))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [\"NLAE\", \"LAE\"])\n",
    "    disp.plot()\n",
    "    # plt.figure(dpi = 200)\n",
    "    plt.savefig(f\"/pscratch/sd/j/juikuan/DESI_LAE_diagram/confusion_matrix_{current_time}.jpg\", bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "\n",
    "    return output, torch.tensor(label).permute(1, 0, 2), diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f\"/pscratch/sd/j/juikuan/DESI_LAE_model/model_compact1_0.898_0.846_0.394_2024-09-24 08:17:00.782281.pt\")\n",
    "output, label, diff = test_perform(model = model, spectra = x_test, label = y_test, spectra_info = spectra_info, plot_wrong = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mb79cd0YnNrr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_LAE(model):\n",
    "  with torch.no_grad():\n",
    "    data = torch.tensor(LAE_flux_test).to(device).float()\n",
    "    model = model.to(device).float()\n",
    "    output, x_scale_1, x1_1, x1_2, x1_3, x1_4, x1_5, x1_6, x1_7, x_cropped, x_scale_2, x_scale_3, x3_1, x3_2, x_cropped2 = model(data)\n",
    "  return x_cropped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimal_perform(search_space, num_samples = 12):\n",
    "    acc1 = []\n",
    "    acc2 = []\n",
    "    n = 0\n",
    "    for i in range(0, num_samples):\n",
    "        n += 1\n",
    "        print(\"=======================================================================================================================\")\n",
    "        print(f\"No.{n} trial:\")\n",
    "        model, train_loss, test_loss, test_acc_1, test_acc_2, test_acc_3, output1_record_train, output2_record_train, output3_record_train, output1_record_test, output2_record_test, output3_record_test = build_model(config = search_space, ray_tune = False)\n",
    "        acc1.append(np.max(test_acc_1))\n",
    "        acc2.append(test_acc_2[test_acc_1.index(max(test_acc_1))])\n",
    "    return acc1, acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxjmJ44zHLVD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": 0.005368,\n",
    "    \"ks1_1\": 21,\n",
    "    \"ks3_1\": 3,\n",
    "    \"ks3_2\": 3,\n",
    "    \"ks4_1\": 3,\n",
    "    \"ks4_2\": 3,\n",
    "    \"batch\": 8,\n",
    "    \"ks_ratio\": 1.949864296,\n",
    "    \"out_ch4\": 512,\n",
    "    \"ps\": 3,\n",
    "    \"lw1\": 1,\n",
    "    \"lw2\": 1 / 5,\n",
    "    \"lw3\": 1 / 2 * 10 ** -2,\n",
    "    \"w1\": 64,\n",
    "    \"w2\": 256,\n",
    "    \"w3\": 128,\n",
    "    \"rescale1\": \"mean\",\n",
    "    \"rescale2\": \"mean\",\n",
    "    \"rescale3\": \"mean\",\n",
    "    \"LAE_w\": False,\n",
    "    \"ratio\": 1,\n",
    "    \"thres\": 0.544750558,\n",
    "    \"factor\": 2.564858051\n",
    "}\n",
    "\n",
    "acc1, acc2 = optimal_perform(search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "R_H0efrzpNuz",
    "outputId": "ab40c624-6135-4280-ae39-c7d4fd731163",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load(f\"../DESI_LAE_model/model_0.979_0.979_0.881_2024-02-07 07:13:17.397448.pt\")\n",
    "output, refer, diff = test_metrics(model, plot_wrong = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "08Sor68hhBGX",
    "outputId": "435affd2-87f2-4f0c-8246-a14dc0086e46",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss_iter(test_loss = [i.item() for i in test_loss], train_loss = [i.item() for i in train_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "4hLwGjgTiZ7g",
    "outputId": "9e407f5b-8150-4686-d572-0bb262066fd8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_test_accuracy(test_acc1 = test_acc_1, test_acc2 = test_acc_2, test_acc3 = test_acc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "L7xhea6rY-Ls",
    "outputId": "9032f088-28b2-4ac9-ddea-fced063667c8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(output1_record_train) - 1):\n",
    "  plt.close()\n",
    "  plt.figure(figsize = (16, 5))\n",
    "  plot_scatter(x = output1_record_train[i][1].to(\"cpu\"), y = output1_record_train[i][0].to(\"cpu\"), c = \"m\", ylabel = \"Predicted Position\", xlabel = \"True Position\", position = 1)\n",
    "  plot_scatter(x = output2_record_train[i][1].to(\"cpu\"), y = output2_record_train[i][0].to(\"cpu\"), c = \"m\", ylabel = \"Predicted Percentage\", xlabel = \"True Percentage\", position = 2)\n",
    "  plot_scatter(x = output3_record_train[i][1].to(\"cpu\"), y = output3_record_train[i][0].to(\"cpu\"), c = \"m\", ylabel = \"Predicted FWHM\", xlabel = \"True FWHM\", position = 3)\n",
    "\n",
    "  plot_scatter(x = output1_record_test[i][1].to(\"cpu\"), y = output1_record_test[i][0].to(\"cpu\"), c = \"y\", ylabel = \"Predicted Position\", xlabel = \"True Position\", position = 1)\n",
    "  plot_scatter(x = output2_record_test[i][1].to(\"cpu\"), y = output2_record_test[i][0].to(\"cpu\"), c = \"y\", ylabel = \"Predicted Percentage\", xlabel = \"True Percentage\", position = 2)\n",
    "  plot_scatter(x = output3_record_test[i][1].to(\"cpu\"), y = output3_record_test[i][0].to(\"cpu\"), c = \"y\", ylabel = \"Predicted FWHM\", xlabel = \"True FWHM\", position = 3)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcgnNE-3dQE9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_cropped2 = check_LAE(model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bSvkDC16noR8",
    "outputId": "570a0dbf-66d5-4c57-b04a-5bde6a585e5f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in x_cropped2:\n",
    "  plt.close()\n",
    "  plt.plot(i[0].to(\"cpu\"))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ia5ZyM9IkAOs"
   },
   "outputs": [],
   "source": [
    "spectra_train, spectra_test = train_test_split(LAE_spectra, test_size = 0.2, random_state = 2)\n",
    "x_range = np.linspace(0, 2438, x_cropped2.shape[-1])\n",
    "for i in range(0, x_cropped2.shape[0]):\n",
    "  plt.close()\n",
    "  plt.rcParams['figure.figsize'] = [16, 4]\n",
    "  plt.plot(x_range, x_scale_1[i][0].to(\"cpu\"), c = \"k\", lw = 1)\n",
    "  plt.plot(spectra_test[i][\"flux\"], alpha = 0.5, c = \"r\", lw = 1)\n",
    "  plt.title(spectra_test[i]['specid'])\n",
    "  plt.savefig(\"/content/drive/MyDrive/CNN/result/x_scale_1/\" + str(spectra_test[i]['specid']) + \".jpg\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGe7N8eZqjzU"
   },
   "outputs": [],
   "source": [
    "x_range = np.linspace(0, len(x_cropped[0][0]), x_scale_3.shape[-1])\n",
    "for i in range(0, x_scale_3.shape[0]):\n",
    "  plt.close()\n",
    "  plt.rcParams['figure.figsize'] = [16, 4]\n",
    "  # plt.plot(x_range, x_cropped[i][0].to(\"cpu\"), c = \"k\", lw = 1, alpha = 0.5)\n",
    "  # plt.plot(x_range, x_cropped[i][1].to(\"cpu\"), c = \"r\", lw = 1, alpha = 0.5)\n",
    "  plt.plot(x_range, x_scale_2[i][0].to(\"cpu\"), c = \"k\", lw = 1)\n",
    "  plt.plot(x_range, x_scale_2[i][1].to(\"cpu\"), c = \"r\", lw = 1)\n",
    "  plt.title(spectra_test[i]['specid'])\n",
    "  plt.savefig(\"/content/drive/MyDrive/CNN/result/x_scale_3/\" + str(spectra_test[i]['specid']) + \".jpg\")\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
